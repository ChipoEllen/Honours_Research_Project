{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL INJECTION DETECTION USING GRU AND ONE DIMENSION CNN-GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install numpy \n",
    "#%pip install keras\n",
    "\n",
    "#%pip install pandas\n",
    "#%pip install matplotlib\n",
    "\n",
    "#%pip uninstall tensorflow keras -y\n",
    "#%pip install tensorflow\n",
    "#%pip install scikit-learn\n",
    "#%pip install tensorflow\n",
    "\n",
    "#%pip install seaborn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation of the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "# Dataset exploring\n",
    "import os\n",
    "# Dataset generation\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Transfer learning\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Optimizer\n",
    "from keras.optimizers import Adam\n",
    "# Keras layers\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, AveragePooling2D\n",
    "# Keras model\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing and Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class                Number of Instances \n",
      "-----------------------------------------\n",
      "benign               20867               \n",
      "SQL injection        20867               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "#D:/AI model for research\n",
    "csv_file_path = 'D:/AI model for research/Book1.csv'\n",
    "\n",
    "# Read the CSV file using the correct delimiter\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path, delimiter=';', quotechar='\"', on_bad_lines='skip')\n",
    "\n",
    "    # Filter the DataFrame for relevant classes only\n",
    "    relevant_classes = ['benign', 'SQL injection']\n",
    "    filtered_df = df[df['attack_type'].isin(relevant_classes)]\n",
    "\n",
    "    # Count instances for each relevant class\n",
    "    class_counts = filtered_df['attack_type'].value_counts()\n",
    "\n",
    "    # Prepare the table header\n",
    "    header = f\"{'Class':<20} {'Number of Instances':<20}\"\n",
    "    separator = \"-\" * len(header)\n",
    "    output = f\"{header}\\n{separator}\\n\"\n",
    "\n",
    "    # Add the counts to the output\n",
    "    for attack_type in relevant_classes:\n",
    "        count = class_counts.get(attack_type, 0)  # Get the count, default to 0 if not present\n",
    "        output += f\"{attack_type:<20} {count:<20}\\n\"\n",
    "\n",
    "    # Print the formatted table\n",
    "    print(output)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining data from the csv files to use for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'D:/AI model for research/Training_dataset.csv'\n",
    "TEST_PATH = 'D:/AI model for research/Testing_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data and training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1D CNN-GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other code with metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer saved to D:/AI model for research/tokenizer.pkl\n",
      "Max sequence length saved to D:/AI model for research/max_sequence_length.pkl\n",
      "\n",
      "Round 1 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ellen\\OneDrive\\Desktop\\ITRI616\\Telescope-Simulator\\.conda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\n",
      "\n",
      "Round 2 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ellen\\OneDrive\\Desktop\\ITRI616\\Telescope-Simulator\\.conda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\n",
      "\n",
      "Round 3 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ellen\\OneDrive\\Desktop\\ITRI616\\Telescope-Simulator\\.conda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n",
      "\n",
      "Round 4 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ellen\\OneDrive\\Desktop\\ITRI616\\Telescope-Simulator\\.conda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step\n",
      "\n",
      "Round 5 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ellen\\OneDrive\\Desktop\\ITRI616\\Telescope-Simulator\\.conda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step\n",
      "\n",
      "--- Final Metrics ---\n",
      "Accuracy: 0.9480 ± 0.0028\n",
      "Precision: 0.9484 ± 0.0032\n",
      "Recall: 0.9480 ± 0.0028\n",
      "F1 Score: 0.9480 ± 0.0027\n",
      "F2 Score: 0.9513 ± 0.0093\n",
      "Cohen's Kappa: 0.8961 ± 0.0055\n",
      "ROC-AUC: 0.9903 ± 0.0012\n",
      "Log-Loss: 0.1299 ± 0.0054\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, \n",
    "                             confusion_matrix, cohen_kappa_score, roc_auc_score, log_loss, precision_recall_fscore_support)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('D:/AI model for research/Full_Dataset_Equal.csv', sep=';')\n",
    "\n",
    "# Filter only 'benign' and 'SQL Injection'\n",
    "data = data[data['attack_type'].isin(['benign', 'SQL injection'])]\n",
    "\n",
    "# Extract features and labels\n",
    "X = data['payload'].values\n",
    "y = data['attack_type'].values\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)  # Encodes 'benign' as 0 and 'SQL Injection' as 1\n",
    "\n",
    "# One-hot encode the labels for model training\n",
    "y_onehot = to_categorical(y, num_classes=2)\n",
    "\n",
    "# SQL injection keywords to add to the tokenizer vocabulary\n",
    "sql_injection_keywords = ['SELECT', 'UNION', 'DROP', 'INSERT', 'DELETE', '--', 'OR', 'AND', 'FROM', \n",
    "                          'WHERE', 'TABLE', 'DATABASE', 'ADMIN', 'PASSWORD', 'EXEC', 'CHAR', \n",
    "                          'VARCHAR', 'CONCAT', 'SLEEP', 'BENCHMARK']\n",
    "\n",
    "# Tokenization and padding with OOV handling and added SQL keywords\n",
    "num_words = 10000  # Set a higher number of words for the tokenizer\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token='<OOV>')\n",
    "\n",
    "# Manually add SQL injection keywords\n",
    "tokenizer.fit_on_texts(sql_injection_keywords)\n",
    "\n",
    "# Fit the tokenizer on the dataset\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# Save the tokenizer for later use\n",
    "tokenizer_save_path = 'D:/AI model for research/tokenizer.pkl'\n",
    "with open(tokenizer_save_path, 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print(f\"Tokenizer saved to {tokenizer_save_path}\")\n",
    "\n",
    "# Convert the text to sequences and pad them\n",
    "max_sequence_length = 100  # Set a fixed max sequence length\n",
    "X_tokenized = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_tokenized, maxlen=max_sequence_length)\n",
    "\n",
    "# Save max_sequence_length\n",
    "max_sequence_length_path = 'D:/AI model for research/max_sequence_length.pkl'\n",
    "with open(max_sequence_length_path, 'wb') as f:\n",
    "    pickle.dump(max_sequence_length, f)\n",
    "print(f\"Max sequence length saved to {max_sequence_length_path}\")\n",
    "\n",
    "# Apply MinMaxScaler to scale the padded sequences between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Number of test rounds\n",
    "num_rounds = 5  # Set the number of rounds\n",
    "\n",
    "# Storage for metrics across rounds\n",
    "accuracy_scores, precision_scores, recall_scores, f1_scores, f2_scores = [], [], [], [], []\n",
    "kappa_scores, auc_scores, log_losses = [], [], []\n",
    "\n",
    "# Run multiple rounds of training and evaluation\n",
    "for round_num in range(num_rounds):\n",
    "    print(f\"\\nRound {round_num + 1} / {num_rounds}\")\n",
    "\n",
    "    # Split data into train, validation, and test sets\n",
    "    X_rest, X_test, y_rest_onehot, y_test_onehot = train_test_split(X_padded, y_onehot, test_size=0.1, shuffle=True)\n",
    "\n",
    "    # Split remaining 90% into 70% training and 20% validation\n",
    "    X_train, X_val, y_train_onehot, y_val_onehot = train_test_split(X_rest, y_rest_onehot, test_size=0.2222, shuffle=True)\n",
    "\n",
    "    # Reshape and scale the data\n",
    "    X_train_flat = X_train.reshape(-1, X_train.shape[1])\n",
    "    X_val_flat = X_val.reshape(-1, X_val.shape[1])\n",
    "    X_test_flat = X_test.reshape(-1, X_test.shape[1])\n",
    "\n",
    "    # Fit and transform\n",
    "    X_train_scaled = scaler.fit_transform(X_train_flat).reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_val_scaled = scaler.transform(X_val_flat).reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "    X_test_scaled = scaler.transform(X_test_flat).reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # Build the CNN-GRU model\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Conv1D, MaxPooling1D, Dropout, GRU, Flatten, Dense\n",
    "    from keras.optimizers import Adam\n",
    "\n",
    "    cnn_gru_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(max_sequence_length, 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        GRU(32, return_sequences=True),\n",
    "        GRU(32),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    cnn_gru_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = cnn_gru_model.fit(X_train_scaled, y_train_onehot, epochs=7, validation_data=(X_val_scaled, y_val_onehot), batch_size=32, verbose=0)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    y_pred_prob = cnn_gru_model.predict(X_test_scaled)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    y_test = np.argmax(y_test_onehot, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "    recall_scores.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    f2_scores.append(fbeta_score(y_test, y_pred, beta=2))\n",
    "    kappa_scores.append(cohen_kappa_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_pred_prob[:, 1]))\n",
    "    log_losses.append(log_loss(y_test, y_pred_prob))\n",
    "\n",
    "# Calculate and print mean and std of metrics across all rounds\n",
    "print(\"\\n--- Final Metrics ---\")\n",
    "print(f\"Accuracy: {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}\")\n",
    "print(f\"Precision: {np.mean(precision_scores):.4f} ± {np.std(precision_scores):.4f}\")\n",
    "print(f\"Recall: {np.mean(recall_scores):.4f} ± {np.std(recall_scores):.4f}\")\n",
    "print(f\"F1 Score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n",
    "print(f\"F2 Score: {np.mean(f2_scores):.4f} ± {np.std(f2_scores):.4f}\")\n",
    "print(f\"Cohen's Kappa: {np.mean(kappa_scores):.4f} ± {np.std(kappa_scores):.4f}\")\n",
    "print(f\"ROC-AUC: {np.mean(auc_scores):.4f} ± {np.std(auc_scores):.4f}\")\n",
    "print(f\"Log-Loss: {np.mean(log_losses):.4f} ± {np.std(log_losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the tokenizer used for training the 1D CNN-GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# For CNN-GRU model\n",
    "#with open('D:/RESEARCH DATASET OF 10000/tokenizer_cnn_gru.pkl', 'wb') as handle:\n",
    "#    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "# Save the tokenizer and maxlen together\n",
    "save_dir = 'D:/AI model for research/'\n",
    "\n",
    "with open(f'{save_dir}tokenizer_cnn_gru.pkl', 'wb') as handle:\n",
    "    pickle.dump({'tokenizer': tokenizer, 'maxlen': max_sequence_length}, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the 1D CNN-GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-GRU model saved to D:/AI model for research/CNN-GRU_SQL_Injection_Detector1.h5\n"
     ]
    }
   ],
   "source": [
    "# Save the CNN-GRU model\n",
    "cnn_gru_model_path = os.path.join('D:/AI model for research/', 'CNN-GRU_SQL_Injection_Detector1.h5')\n",
    "cnn_gru_model.save(cnn_gru_model_path)\n",
    "print(f'CNN-GRU model saved to {cnn_gru_model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, \n",
    "                             confusion_matrix, cohen_kappa_score, roc_auc_score, log_loss, precision_recall_fscore_support)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('D:/AI model for research/Full_Dataset_Equal.csv', sep=';')\n",
    "\n",
    "# Filter only 'benign' and 'SQL Injection'\n",
    "data = data[data['attack_type'].isin(['benign', 'SQL injection'])]\n",
    "\n",
    "# Extract features and labels\n",
    "X = data['payload'].values\n",
    "y = data['attack_type'].values\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)  # Encodes 'benign' as 0 and 'SQL Injection' as 1\n",
    "\n",
    "# One-hot encode the labels for model training\n",
    "y_onehot = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Tokenization and padding with OOV handling\n",
    "num_words = 10000  # Set a higher number of words for the tokenizer\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token='<OOV>')  # Set the oov_token for unseen words\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# Save the tokenizer for later use\n",
    "tokenizer_save_path = 'D:/AI model for research/tokenizer.pkl'\n",
    "with open(tokenizer_save_path, 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print(f\"Tokenizer saved to {tokenizer_save_path}\")\n",
    "\n",
    "# Convert the text to sequences and pad them\n",
    "max_sequence_length = 100  # Set a fixed max sequence length\n",
    "X_tokenized = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_tokenized, maxlen=max_sequence_length)\n",
    "\n",
    "# Save max_sequence_length\n",
    "max_sequence_length_path = 'D:/AI model for research/max_sequence_length.pkl'\n",
    "with open(max_sequence_length_path, 'wb') as f:\n",
    "    pickle.dump(max_sequence_length, f)\n",
    "print(f\"Max sequence length saved to {max_sequence_length_path}\")\n",
    "\n",
    "# Apply MinMaxScaler to scale the padded sequences between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "X_rest, X_test, y_rest_onehot, y_test_onehot = train_test_split(X_padded, y_onehot, test_size=0.1, shuffle=False)\n",
    "\n",
    "# Split remaining 90% into 70% training and 20% validation\n",
    "X_train, X_val, y_train_onehot, y_val_onehot = train_test_split(X_rest, y_rest_onehot, test_size=0.2222, shuffle=False)\n",
    "\n",
    "# Reshape the data for scaling\n",
    "X_train_flat = X_train.reshape(-1, X_train.shape[1])\n",
    "X_val_flat = X_val.reshape(-1, X_val.shape[1])\n",
    "X_test_flat = X_test.reshape(-1, X_test.shape[1])\n",
    "\n",
    "# Fit the scaler on training data and transform\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_val_scaled = scaler.transform(X_val_flat)\n",
    "X_test_scaled = scaler.transform(X_test_flat)\n",
    "\n",
    "# Reshape back after scaling\n",
    "X_train_scaled = X_train_scaled.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val_scaled = X_val_scaled.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test_scaled = X_test_scaled.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build the GRU model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "gru_model = Sequential([\n",
    "    GRU(32, return_sequences=True, input_shape=(max_sequence_length, 1)),\n",
    "    GRU(32),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the GRU model\n",
    "gru_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "class_weights = {0: 1.0, 1: 5.0}  # Increase weight for 'SQL Injection'\n",
    "\n",
    "# Train the model and capture the history\n",
    "history = gru_model.fit(X_train_scaled, y_train_onehot, \n",
    "                        epochs=5, \n",
    "                        validation_data=(X_val_scaled, y_val_onehot), \n",
    "                        batch_size=16,\n",
    "                        class_weight=class_weights)\n",
    "\n",
    "# End training time\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Number of parameters\n",
    "total_params = gru_model.count_params()\n",
    "print(f\"Total number of parameters: {total_params}\")\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred_prob = gru_model.predict(X_test_scaled)  # Get the probabilities\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Evaluate model's performance\n",
    "y_test = np.argmax(y_test_onehot, axis=1)  # Convert one-hot to labels for evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f2 = precision_recall_fscore_support(y_test, y_pred, beta=2, average='binary')[2]  # F2 score\n",
    "cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob[:, 1])\n",
    "logloss = log_loss(y_test, y_pred_prob)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "# Calculate False Positives, False Negatives\n",
    "false_positives = FP\n",
    "false_negatives = FN\n",
    "true_negatives = TN\n",
    "true_positives = TP\n",
    "\n",
    "# Proportion of false positives\n",
    "proportion_false_positives = false_positives / (false_positives + true_negatives)\n",
    "\n",
    "# Plot accuracy and loss over epochs\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC curve and AUC for the positive class (SQL Injection)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Print all metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"F2-Score: {f2:.4f}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"Log-Loss: {logloss:.4f}\")\n",
    "print(f\"False Positives: {false_positives}\")\n",
    "print(f\"False Negatives: {false_negatives}\")\n",
    "print(f\"True Positives: {true_positives}\")\n",
    "print(f\"True Negatives: {true_negatives}\")\n",
    "print(f\"Proportion of False Positives: {proportion_false_positives:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Save the GRU model\n",
    "model_save_path = 'D:/AI model for research/gru_model.h5'  # Update this path as needed\n",
    "gru_model.save(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the tokenizer used by GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# For GRU model\n",
    "#with open('D:/RESEARCH DATASET OF 10000/tokenizer_gru.pkl', 'wb') as handle:\n",
    "#    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save the same for GRU if using different tokenizer or maxlen\n",
    "with open(f'{save_dir}tokenizer_gru.pkl', 'wb') as handle:\n",
    "    pickle.dump({'tokenizer': tokenizer, 'maxlen': max_sequence_length}, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the  GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-GRU model saved to D:/AI model for research/CNN-GRU_SQL_Injection_Detector.h5\n",
      "GRU model saved to D:/AI model for research/GRU_SQL_Injection_Detector.h5\n"
     ]
    }
   ],
   "source": [
    "# Create a directory to save the models if it doesn't exist\n",
    "save_dir = 'D:/AI model for research/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Save the CNN-GRU model\n",
    "cnn_gru_model_path = os.path.join(save_dir, 'CNN-GRU_SQL_Injection_Detector.h5')\n",
    "cnn_gru_model.save(cnn_gru_model_path)\n",
    "print(f'CNN-GRU model saved to {cnn_gru_model_path}')\n",
    "\n",
    "# Save the GRU model\n",
    "gru_model_path = os.path.join(save_dir, 'GRU_SQL_Injection_Detector.h5')\n",
    "gru_model.save(gru_model_path)\n",
    "print(f'GRU model saved to {gru_model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing CNN-GRU Model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m24,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m6,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m202\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,880</span> (222.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m56,880\u001b[0m (222.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,878</span> (222.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,878\u001b[0m (222.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3801 - loss: 2.5874\n",
      "Test loss            Test accuracy       \n",
      "3.02                 0.26                \n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       benign       0.00      0.00      0.00      2607\n",
      "SQL injection       0.47      0.36      0.41      6434\n",
      "\n",
      "     accuracy                           0.26      9041\n",
      "    macro avg       0.24      0.18      0.21      9041\n",
      " weighted avg       0.34      0.26      0.29      9041\n",
      "\n",
      "Precision: 0.34\n",
      "Recall: 0.26\n",
      "F1 Score: 0.29\n",
      "\n",
      "Testing GRU Model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m12,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m6,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m202\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,528</span> (173.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,528\u001b[0m (173.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,526</span> (173.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,526\u001b[0m (173.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\u001b[1m281/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9950 - loss: 0.0091"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Test GRU Model\u001b[39;00m\n\u001b[0;32m     79\u001b[0m gru_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/AI model for research/GRU_SQL_Injection_Detector.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 80\u001b[0m test_model(gru_model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGRU\u001b[39m\u001b[38;5;124m'\u001b[39m, X_test_padded_gru)\n",
      "Cell \u001b[1;32mIn[5], line 52\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(model_path, model_name, X_test_padded)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(loaded_model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test data\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m results \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mevaluate(X_test_padded, y_test_encoded)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:<20}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:<20}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:<20}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:<20}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(np\u001b[38;5;241m.\u001b[39mround(results[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m2\u001b[39m), np\u001b[38;5;241m.\u001b[39mround(results[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m2\u001b[39m)))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:433\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    432\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m--> 433\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_function(iterator)\n\u001b[0;32m    434\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    435\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    870\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    871\u001b[0m   )\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1553\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1554\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1555\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1556\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1557\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1558\u001b[0m   )\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load test data\n",
    "test_csv_path = 'D:/AI model for research/Testing_dataset.csv'\n",
    "test_df = pd.read_csv(test_csv_path, delimiter=';')\n",
    "\n",
    "# Extract features and labels\n",
    "X_test = test_df['payload'].values\n",
    "y_test = test_df['attack_type'].values\n",
    "\n",
    "# Preprocess the labels\n",
    "le = LabelEncoder()\n",
    "y_test_encoded = le.fit_transform(y_test)  # Encodes 'benign' as 0 and 'SQL Injection' as 1\n",
    "y_test_encoded = to_categorical(y_test_encoded, num_classes=2)\n",
    "\n",
    "# Load the tokenizer and maxlen used for CNN-GRU model\n",
    "with open('D:/AI model for research/tokenizer_cnn_gru1.pkl', 'rb') as handle:\n",
    "    cnn_gru_data = pickle.load(handle)\n",
    "    tokenizer_cnn_gru = cnn_gru_data['tokenizer']\n",
    "    maxlen_cnn_gru = cnn_gru_data['maxlen']\n",
    "\n",
    "# Tokenize and pad the payloads for CNN-GRU model\n",
    "X_test_sequences_cnn_gru = tokenizer_cnn_gru.texts_to_sequences(X_test)\n",
    "X_test_padded_cnn_gru = pad_sequences(X_test_sequences_cnn_gru, maxlen=maxlen_cnn_gru)\n",
    "\n",
    "# Load the tokenizer and maxlen used for GRU model\n",
    "with open('D:/AI model for research/tokenizer_gru.pkl', 'rb') as handle:\n",
    "    gru_data = pickle.load(handle)\n",
    "    tokenizer_gru = gru_data['tokenizer']\n",
    "    maxlen_gru = gru_data['maxlen']\n",
    "\n",
    "# Tokenize and pad the payloads for GRU model\n",
    "X_test_sequences_gru = tokenizer_gru.texts_to_sequences(X_test)\n",
    "X_test_padded_gru = pad_sequences(X_test_sequences_gru, maxlen=maxlen_gru)\n",
    "\n",
    "# Function to test models\n",
    "def test_model(model_path, model_name, X_test_padded):\n",
    "    print(f\"\\nTesting {model_name} Model:\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = load_model(model_path)\n",
    "    print(loaded_model.summary())\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    results = loaded_model.evaluate(X_test_padded, y_test_encoded)\n",
    "    print('{:<20} {:<20}'.format('Test loss', 'Test accuracy'))\n",
    "    print('{:<20} {:<20}'.format(np.round(results[0], 2), np.round(results[1], 2)))\n",
    "\n",
    "    # Predictions and Metrics\n",
    "    predictions = loaded_model.predict(X_test_padded)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    true_classes = np.argmax(y_test_encoded, axis=1)\n",
    "    class_labels = ['benign', 'SQL injection']\n",
    "\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "    print(report)\n",
    "\n",
    "    precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "    recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "    f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Test CNN-GRU Model\n",
    "cnn_gru_model_path = 'D:/AI model for research/CNN-GRU_SQL_Injection_Detector.h5'\n",
    "test_model(cnn_gru_model_path, 'CNN-GRU', X_test_padded_cnn_gru)\n",
    "\n",
    "# Test GRU Model\n",
    "gru_model_path = 'D:/AI model for research/GRU_SQL_Injection_Detector.h5'\n",
    "test_model(gru_model_path, 'GRU', X_test_padded_gru)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GUI to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 686ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved CNN-GRU model, tokenizer, scaler, and max_sequence_length\n",
    "cnn_gru_model_path = 'D:/AI model for research/cnn_gru_sql_injection_model.h5'\n",
    "tokenizer_path = 'D:/AI model for research/tokenizer.pkl'\n",
    "scaler_path = 'D:/AI model for research/minmax_scaler.pkl'\n",
    "max_sequence_length_path = 'D:/AI model for research/max_sequence_length.pkl'\n",
    "\n",
    "# Load tokenizer, scaler, and max_sequence_length\n",
    "try:\n",
    "    with open(tokenizer_path, 'rb') as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    with open(max_sequence_length_path, 'rb') as f:\n",
    "        max_sequence_length = pickle.load(f)\n",
    "    cnn_gru_model = load_model(cnn_gru_model_path, compile=False)\n",
    "except Exception as e:\n",
    "    messagebox.showerror(\"Error\", f\"Failed to load model or related files: {str(e)}\")\n",
    "    raise e\n",
    "\n",
    "# Function to test the input SQL query\n",
    "def test_sql_injection():\n",
    "    # Get the input from the text box\n",
    "    user_input = entry.get().strip()\n",
    "    \n",
    "    # Validate input\n",
    "    if not user_input:\n",
    "        messagebox.showerror(\"Input Error\", \"Please enter a valid SQL query.\")\n",
    "        return\n",
    "    \n",
    "    # Preprocess the input: Tokenize and pad (OOV token already handled by tokenizer)\n",
    "    sequences = tokenizer.texts_to_sequences([user_input])\n",
    "    \n",
    "    if len(sequences[0]) == 0:\n",
    "        messagebox.showerror(\"Input Error\", \"Invalid input after tokenization. Please try again with a proper SQL query.\")\n",
    "        return\n",
    "\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "    \n",
    "    # Scale the padded sequences\n",
    "    padded_sequences_scaled = scaler.transform(padded_sequences)  # Ensure the sequence length matches training\n",
    "    padded_sequences_scaled = np.expand_dims(padded_sequences_scaled, axis=2)  # Reshape for the model input\n",
    "    \n",
    "    # Predict using the loaded model\n",
    "    prediction = cnn_gru_model.predict(padded_sequences_scaled)\n",
    "    predicted_class = np.argmax(prediction, axis=1)[0]  # Extract the single predicted class\n",
    "    confidence_score = prediction[0][predicted_class] * 100  # Confidence score in percentage\n",
    "    \n",
    "    # Display the result with confidence score\n",
    "    if predicted_class == 0:\n",
    "        result = f\"Benign query with {confidence_score:.2f}% confidence\"\n",
    "    else:\n",
    "        result = f\"SQL Injection (malicious) with {confidence_score:.2f}% confidence\"\n",
    "    \n",
    "    messagebox.showinfo(\"Result\", result)\n",
    "\n",
    "# Create the GUI window\n",
    "root = tk.Tk()\n",
    "root.title(\"SQL Injection Detector\")\n",
    "\n",
    "# Create and place the input text box\n",
    "label = tk.Label(root, text=\"Enter SQL Query:\")\n",
    "label.pack(pady=10)\n",
    "entry = tk.Entry(root, width=50)\n",
    "entry.pack(pady=10)\n",
    "\n",
    "# Create and place the test button\n",
    "test_button = tk.Button(root, text=\"Test Query\", command=test_sql_injection)\n",
    "test_button.pack(pady=20)\n",
    "\n",
    "# Start the GUI event loop\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
